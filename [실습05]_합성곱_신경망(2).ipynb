{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[실습05] 합성곱 신경망(2).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLVOwhQmINxZLulZHAF2rF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiteday/Deep-Learning_2021/blob/main/%5B%EC%8B%A4%EC%8A%B505%5D_%ED%95%A9%EC%84%B1%EA%B3%B1_%EC%8B%A0%EA%B2%BD%EB%A7%9D(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoK4Tn949YDV"
      },
      "source": [
        "##1.Settings\n",
        "1)Important required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClIdJcf1BTFe"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('file1.py','wb').write(src)\n",
        "import file1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAAytBVDDqiV"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcTsf2YJ_aHN"
      },
      "source": [
        "2) Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlOeiPUJBWsV"
      },
      "source": [
        "batch_size =16\n",
        "learning_rate=0.0001\n",
        "epoch=20\n",
        "\n",
        "n_node = 1024\n",
        "dropratio = 0.5\n",
        "\n",
        "imgsize = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iiv4aW0DFNw"
      },
      "source": [
        "# 2.Data Loader\n",
        "트레이닝 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbF940wmBblK"
      },
      "source": [
        "#연습용 시험문제이므로 변주를 많이 줌\n",
        "img_dir = \"/content/drive/MyDrive/DeepLearning/car/train\"\n",
        "train_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
        "              transforms.CenterCrop(imgsize*2),\n",
        "              transforms.RandomCrop(imgsize),\n",
        "              transforms.RandomHorizontalFlip(),\n",
        "\n",
        "              transforms.Resize(imgsize),\n",
        "              transforms.ToTensor()\n",
        "              ]))\n",
        "print(train_data.__len__())\n",
        "\n",
        "train_batch = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers= 2)                                                           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3a-vp2hBdr2"
      },
      "source": [
        "#2. Dev data (validation data)\n",
        "#그 자체가 인식이 맞는지 중요\n",
        "img_dir = \"/content/drive/MyDrive/DeepLearning/car/val\"\n",
        "dev_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
        "              transforms.CenterCrop(size = imgsize),\n",
        "              transforms.Resize(imgsize),\n",
        "              transforms.ToTensor()\n",
        "              ]))\n",
        "print(dev_data.__len__())\n",
        "\n",
        "dev_batch = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers= 2)                                                           \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfBtMck0BgOn"
      },
      "source": [
        "#3. Test data \n",
        "\n",
        "img_dir = \"/content/drive/MyDrive/DeepLearning/car/test\"\n",
        "test_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
        "              transforms.CenterCrop(size = imgsize),\n",
        "              transforms.Resize(imgsize),\n",
        "              transforms.ToTensor()\n",
        "              ]))\n",
        "print(test_data.__len__())\n",
        "\n",
        "test_batch = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers= 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7dEmrYnBiJI"
      },
      "source": [
        "nclass = len(train_data.classes)\n",
        "print(\"# of classes : %d\" %nclass)\n",
        "print(train_data.classes)\n",
        "print(train_data.class_to_idx)\n",
        "print(train_data.__len__())\n",
        "\n",
        "print(\"Training : %d, Dev: %d, Test: %d\" %(train_data.__len__(), dev_data.__len__(), test_data.__len__()))\n",
        "\n",
        "#toy example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO70Xn5QJ6HT"
      },
      "source": [
        "print(train_data.classes)\n",
        "print(dev_data.classes)\n",
        "print(test_data.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHqaVqHNM_PX"
      },
      "source": [
        "# 3.Model\n",
        "1) Pretrained VGG Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_ihdRZMLvo0"
      },
      "source": [
        "vgg = models.vgg19(pretrained=True) #만약 false이면 구조만 들어오고 미리 학습된 세타값이 들어오지 않음\n",
        "\n",
        "for name,module in vgg.named_children():\n",
        "  print(name)\n",
        "\n",
        "print(list(vgg.children())[0])\n",
        "print(list(vgg.children())[-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfFzqhVQQKoK"
      },
      "source": [
        "print(list(vgg.children())[0][:4]) #[0][:8] #8까지 커스텀해서 쓸거!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQVqZmUJQq1x"
      },
      "source": [
        "2) Customized Fully model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI3Lg4KkQgWk"
      },
      "source": [
        "base_dim =64\n",
        "fsize = imgsize/32\n",
        "\n",
        "class MyVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyVGG, self).__init__()\n",
        "        self.layer0=nn.Sequential(*list(vgg.children())[0])\n",
        "\n",
        "        self.layer1=nn.Sequential(\n",
        "            nn.Linear(int(8 * base_dim * fsize *fsize), n_node),\n",
        "            nn.BatchNorm1d(n_node),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(dropratio),\n",
        "\n",
        "            nn.Linear(n_node, n_node),\n",
        "            nn.BatchNorm1d(n_node),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(dropratio),\n",
        "            \n",
        "            nn.Linear(n_node, n_node),\n",
        "            nn.BatchNorm1d(n_node),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(dropratio),\n",
        "\n",
        "            nn.Linear(n_node, nclass),\n",
        "        )\n",
        "        #weight initialization\n",
        "        for m in self.layer1.modules():\n",
        "          if isinstance(m, (nn.Conv2d)):\n",
        "            init.kaiming_normal(int(m.weight.data))\n",
        "            m.bias.data.fill_(0)\n",
        "          if isinstance(m, nn.Linear):\n",
        "            init.kaiming_normal((m.weight.data))\n",
        "            m.bias.data.fill_(0)\n",
        "    def forward(self, x):\n",
        "      out = self.layer0(x)\n",
        "      out = out.view(out.size(0), -1)\n",
        "      out = self.layer1(out)\n",
        "      return out\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnjd5j0KUrE9"
      },
      "source": [
        "3) Model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5BobsBUSqw-"
      },
      "source": [
        "model = MyVGG().cuda()\n",
        "\n",
        "for params in model.layer0.parameters():\n",
        "  params.required_grad = False\n",
        "\n",
        "for params in model.layer1.parameters():\n",
        "  params.required_grad = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "393ynGMhY6UI"
      },
      "source": [
        "for name in model.children():\n",
        "  print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8cKpyJwWajh"
      },
      "source": [
        "# 4. Optimizer & Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn9z_yWVWek5"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.layer1.parameters(),lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSRclt5JY9sP"
      },
      "source": [
        "# 5. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L33ZLm5Y8PR"
      },
      "source": [
        "import utils\n",
        "\n",
        "total_time =0\n",
        "disp_step = 10\n",
        "\n",
        "to_train = True\n",
        "if (to_train==False):\n",
        "  netname = '/content/gdrive/MyDrive/DeepLearning/car/bustruck_vgg19_10.pkl'\n",
        "  model = torch.load(netname)\n",
        "\n",
        "else :\n",
        "  print(\"3 layer, n_node, %d, dropratio: %.2f\" % (n_node, dropratio))\n",
        "  model.eval()\n",
        "  train_corr = utils.ComputeCorr(train_batch, model)\n",
        "  dev_corr = utils.ComputeCorr(dev_batch, model)\n",
        "  test_corr = utils.ComputeCorr(test_batch, model)\n",
        "  print(\"Correct of train : %.2f, dev : %.2f, test : %.2f\"\n",
        "        %(train_corr, dev_corr, test_corr))\n",
        "  model.train()\n",
        "\n",
        "  netname = '/content/drive/MyDrive/DeepLearning/car/bustruck_vgg19'\n",
        "\n",
        "  x_epoch =[]\n",
        "  y_train_err =[]\n",
        "  y_dev_err = []\n",
        "  y_test_err = []\n",
        "\n",
        "  x_epoch.append(0)\n",
        "  y_train_err.append(100.0-train_corr)\n",
        "  y_dev_err.append(100.0-dev_corr)\n",
        "  y_test_err.append(100.0-test_corr)\n",
        "\n",
        "  for i in range(epoch):\n",
        "    start_time = time.time()\n",
        "    print(\"%d..\" %i)\n",
        "    for img,label in train_batch:\n",
        "      img = Variable(img).cuda()\n",
        "      label = Variable(label).cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(img)\n",
        "      loss = loss_func(output, label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    total_time += duration\n",
        "    if (i % disp_step == 0) or (i== epoch -1) :\n",
        "      torch.save(model, netname +'_%d.pki' %i, )\n",
        "      print(\"\\n[%d/%d] loss: %.3f,\" %(i, epoch, (loss.cpu()).data.numpy())),\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      train_corr = utils.ComputeCorr(train_batch, model)\n",
        "      dev_corr = utils.ComputeCorr(dev_batch, model)\n",
        "      test_corr = utils.ComputeCorr(test_batch, model)\n",
        "      print(\"Correct of train : %.2f, dev : %.2f, test : %.2f\"\n",
        "        %(train_corr, dev_corr, test_corr))\n",
        "      model.train()\n",
        "      print(\"time: %.2f sec..\" %(total_time))\n",
        "\n",
        "\n",
        "      x_epoch.append(i+1)\n",
        "      y_train_err.append(100.0-train_corr)\n",
        "      y_dev_err.append(100.0-dev_corr)\n",
        "      y_test_err.append(100.0-test_corr)\n",
        "  print(\"Total time : %.2f sec\" %total_time)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHJe5jsjmE9c"
      },
      "source": [
        "if(to_train) :\n",
        "  plt.plot(x_epoch, y_train_err, color='black', label='train err', linestyle='--')\n",
        "  plt.plot(x_epoch, y_dev_err, color='red', label='dev err')\n",
        "  plt.plot(x_epoch, y_test_err, color='blue', label='test err')\n",
        "\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('err')\n",
        "  plt.title('epoch & err graph')\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kb-277LoIAR"
      },
      "source": [
        "# 6.Evaluation for dev & test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCJz9aT-oNNi"
      },
      "source": [
        "model.eval()\n",
        "utils.EvaluateClassifier(dev_batch, model, dev_data.classes, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDTCk7FQos8L"
      },
      "source": [
        "model.eval()\n",
        "utils.EvaluateClassifier(test_batch, model, test_data.classes, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TdzmIB5pxiq"
      },
      "source": [
        "utils.VisTFPred(dev_batch, model, test_data.classes, batch_size,i_n=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j7RsNgpqmUe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}